{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d16ca8",
   "metadata": {},
   "source": [
    "# Recommender Sytem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449d8281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957dd292",
   "metadata": {},
   "source": [
    "We first load all the data we need for the system (check **data_analysis.ipynb** for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe06d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"dataset\"\n",
    "\n",
    "def user_feats():\n",
    "    user_columns = [\n",
    "        \"user_id\", \"onehot_feat0\", \"onehot_feat1\", \"onehot_feat2\", \"onehot_feat3\", \"onehot_feat4\", \"onehot_feat5\",\n",
    "        \"onehot_feat6\", \"onehot_feat7\", \"onehot_feat8\", \"onehot_feat9\", \"onehot_feat10\", \"onehot_feat11\",\n",
    "        \"onehot_feat12\", \"onehot_feat13\", \"onehot_feat14\", \"onehot_feat15\", \"onehot_feat16\", \"onehot_feat17\"\n",
    "    ]\n",
    "\n",
    "    users = pd.read_csv(f\"{DATASET_PATH}/user_features.csv\", usecols=user_columns)\n",
    "\n",
    "    users = users.fillna(0).astype(float)\n",
    "    users['user_id'] = users['user_id'].astype(int)\n",
    "    return users\n",
    "\n",
    "def item_feats():\n",
    "    item_cols = [\n",
    "        'video_id', 'music_id', 'video_tag_id', 'play_cnt',\n",
    "        'play_duration', 'long_time_play_cnt', 'short_time_play_cnt',\n",
    "        'play_progress', 'comment_stay_duration', 'like_cnt',\n",
    "        'cancel_like_cnt', 'comment_cnt', 'delete_comment_cnt',\n",
    "        'comment_like_cnt', 'follow_cnt', 'cancel_follow_cnt',\n",
    "        'share_cnt', 'download_cnt'\n",
    "    ]\n",
    "    \n",
    "    cols_to_aggregate = [\n",
    "        'play_cnt', 'play_duration', 'long_time_play_cnt',\n",
    "        'short_time_play_cnt', 'play_progress', 'comment_stay_duration',\n",
    "        'like_cnt', 'cancel_like_cnt', 'comment_cnt',\n",
    "        'delete_comment_cnt', 'comment_like_cnt', 'follow_cnt',\n",
    "        'cancel_follow_cnt', 'share_cnt', 'download_cnt'\n",
    "    ]\n",
    "    \n",
    "    items = pd.read_csv(f\"{DATASET_PATH}/item_daily_features.csv\", usecols=item_cols)\n",
    "    \n",
    "\n",
    "    agg_items = items.groupby('video_id').agg({\n",
    "        col: 'mean' for col in cols_to_aggregate\n",
    "    }).reset_index()\n",
    "    \n",
    "    last_items = items.sort_values('video_id').drop_duplicates(\n",
    "        subset=\"video_id\", keep=\"last\"\n",
    "    )[['video_id', 'music_id', 'video_tag_id']]\n",
    "    \n",
    "    result = pd.merge(last_items, agg_items, on='video_id')\n",
    "    return result\n",
    "\n",
    "def truth_data():\n",
    "    y_cols = ['user_id', 'video_id', 'watch_ratio']\n",
    "    y = pd.read_csv(f\"{DATASET_PATH}/big_matrix.csv\", usecols=y_cols)\n",
    "    y['watch_ratio'] = y['watch_ratio'].clip(upper=5)\n",
    "    return y\n",
    "\n",
    "user_df = user_feats()\n",
    "item_df = item_feats()\n",
    "y_df = truth_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f90aa",
   "metadata": {},
   "source": [
    "We then process the data to only keep the meaningful values in numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07678e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    merged_user = pd.merge(\n",
    "        y_df, \n",
    "        user_df, \n",
    "        on='user_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Extract user features (all columns except the ones from y_df)\n",
    "    user_cols = [col for col in merged_user.columns if col not in y_df.columns or col == 'user_id']\n",
    "\n",
    "    # Merge item features\n",
    "    final_df = pd.merge(\n",
    "        merged_user,\n",
    "        item_df,\n",
    "        left_on='video_id',\n",
    "        right_on='video_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Get the result column\n",
    "    y_data = final_df['watch_ratio'].values\n",
    "    \n",
    "    # Extract user features (excluding the ID columns and watch_ratio)\n",
    "    user_data = final_df[user_cols].drop('user_id', axis=1).values\n",
    "    \n",
    "    # Extract item features (all columns from item_df except video_id)\n",
    "    item_cols = [col for col in item_df.columns if col != 'video_id']\n",
    "    item_data = final_df[item_cols].values\n",
    "    \n",
    "    return user_data, item_data, y_data\n",
    "\n",
    "user_train, item_train, y_train = load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d78de7",
   "metadata": {},
   "source": [
    "Once the data is loaded, we can split it into **training** data and **testing** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5060a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = 0.2\n",
    "user_train, user_test, item_train, item_test, y_train, y_test  = train_test_split(user_train, item_train, y_train, test_size=split_size)\n",
    "\n",
    "num_user_features = len(user_train[0])\n",
    "num_item_features = len(item_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f4646",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e733a65a",
   "metadata": {},
   "source": [
    "To scale the data, we will use two scaler:\n",
    "- **StandardScaler** for the users and the items\n",
    "- **MinMaxScaler** for the truth values\n",
    "\n",
    "We first fit the scaler with the train data, then we transform both the train and test data with that scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9d2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "userScaler = StandardScaler()\n",
    "user_train = userScaler.fit_transform(user_train)\n",
    "user_test = userScaler.transform(user_test)\n",
    "\n",
    "itemScaler = StandardScaler()\n",
    "item_train = itemScaler.fit_transform(item_train)\n",
    "item_test = itemScaler.transform(item_test)\n",
    "\n",
    "yScaler = MinMaxScaler((-1, 1))\n",
    "y_train = yScaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = yScaler.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c592c1",
   "metadata": {},
   "source": [
    "## Recommender System: Content Based Filtering using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffb87c",
   "metadata": {},
   "source": [
    "For this project, I decided to use **Content Based Filtering** since we do not have relation between users. Moreover, this approach better handles the **cold start** for new users and new items.\n",
    "\n",
    "I used a neural network with Keras as recommender system, as seen in 8th course.\n",
    "\n",
    "Note: if the model was already trained, you can just load it using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2ab3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 19:16:10.873081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-17 19:16:10.905407: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Load the model.\n",
    "model = keras.models.load_model('mymodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d89a682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 20:17:01.995634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-17 20:17:02.157425: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "num_outputs = 48\n",
    "tf.random.set_seed(1)\n",
    "user_NN = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(96, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_outputs)\n",
    "    ]\n",
    ")\n",
    "\n",
    "item_NN = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(96, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_outputs)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# create the user input and point to the base network\n",
    "input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "# create the item input and point to the base network\n",
    "input_item = tf.keras.layers.Input(shape=(num_item_features))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "# compute the dot product of the two vectors vu and vm\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = tf.keras.Model([input_user, input_item], output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e496b",
   "metadata": {},
   "source": [
    "This neural network will perform **regression** to give a watch ratio to all user/video pair. For such models, the best metrics are:\n",
    "- **Mean Absolute Error (MAE)**: express how much the predictions are off\n",
    "- **Root Mean Squared Error (RMSE)**: express how much the predictions are off, but penalizes larger errors more\n",
    "\n",
    "The goal is to minimize both of these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01a0c65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "19580/19580 [==============================] - 155s 8ms/step - loss: 0.0914 - mean_absolute_error: 0.1972 - root_mean_squared_error: 0.3022 - val_loss: 0.0882 - val_mean_absolute_error: 0.1944 - val_root_mean_squared_error: 0.2969\n",
      "Epoch 2/2\n",
      "19580/19580 [==============================] - 153s 8ms/step - loss: 0.0872 - mean_absolute_error: 0.1898 - root_mean_squared_error: 0.2953 - val_loss: 0.0862 - val_mean_absolute_error: 0.1872 - val_root_mean_squared_error: 0.2936\n"
     ]
    }
   ],
   "source": [
    "cost_fn = tf.keras.losses.MeanSquaredError()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss=cost_fn, metrics=[keras.metrics.MeanAbsoluteError(), keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "model.fit(\n",
    "    [user_train, item_train],\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    batch_size=512,\n",
    "    validation_data=([user_test, item_test], y_test)\n",
    ")\n",
    "\n",
    "# Save the model.\n",
    "model.save(\"mymodel.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaaa9b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78318/78318 [==============================] - 150s 2ms/step - loss: 0.0859 - mean_absolute_error: 0.1875 - root_mean_squared_error: 0.2931\n",
      "Testing loss: 0.08589141070842743\n",
      "RAE: 0.1874883621931076\n",
      "RMSE: 0.293072372674942\n"
     ]
    }
   ],
   "source": [
    "loss, rae, rmse = model.evaluate([user_test, item_test], y_test)\n",
    "print(\"Testing loss:\", loss)\n",
    "print(\"RAE:\", rae)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b96639",
   "metadata": {},
   "source": [
    "The testing loss is comparable to the training loss indicating the model has not substantially overfit the training data.\n",
    "\n",
    "Moreover, the RAE and RMSE are both low, meaning that the system predicted pretty well the watch_ratio for each user/video pair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b95e75",
   "metadata": {},
   "source": [
    "## Predict videos to an user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb611baf",
   "metadata": {},
   "source": [
    "For this task, we need as input parameter the id of our user and the number of videos we want to recommend. This function will then print to the terminal the top video ids recommended to our user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67444550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 1s 2ms/step\n",
      "Predict video id 4546 with watch ratio 2.1708658\n",
      "Predict video id 314 with watch ratio 2.1316507\n",
      "Predict video id 908 with watch ratio 2.0876496\n",
      "Predict video id 10318 with watch ratio 2.0545914\n",
      "Predict video id 5162 with watch ratio 2.053305\n",
      "Predict video id 9314 with watch ratio 2.01308\n",
      "Predict video id 10720 with watch ratio 1.9907583\n",
      "Predict video id 1946 with watch ratio 1.9508303\n",
      "Predict video id 498 with watch ratio 1.9384815\n",
      "Predict video id 1305 with watch ratio 1.92878\n"
     ]
    }
   ],
   "source": [
    "# Choose a random user\n",
    "user_id = 1234\n",
    "\n",
    "def predict_existing_user(user_id, num_items=None, get_score=True):\n",
    "    # Extract the user feature vector excluding the user_id column and multiply it by the number of items\n",
    "    user_vecs = user_df.iloc[user_id, 1:].values.reshape(1, -1)\n",
    "    user_vecs = np.tile(user_vecs, (len(item_df), 1))\n",
    "\n",
    "    # Extract the items feature vector excluding the video_id column\n",
    "    item_vecs = item_df.iloc[:, 1:].to_numpy()\n",
    "\n",
    "    # Scale the data using our previous scaler\n",
    "    user_scaled = userScaler.transform(user_vecs)\n",
    "    item_scaled = itemScaler.transform(item_vecs)\n",
    "\n",
    "    # Predict the videos\n",
    "    y_p = model.predict([user_scaled, item_scaled])\n",
    "    y_pu = yScaler.inverse_transform(y_p)\n",
    "\n",
    "    # Sort them to get the most recommended videos\n",
    "    sorted_index = (\n",
    "        np.argsort(-y_pu, axis=0).reshape(-1).tolist()\n",
    "    )\n",
    "\n",
    "    sorted_items = item_vecs[sorted_index]\n",
    "    if num_items != None:\n",
    "        sorted_items = sorted_items[:num_items]\n",
    "    video_ids = [np.where((item_vecs == el).all(axis=1))[0][0] for el in sorted_items]\n",
    "\n",
    "    if get_score:\n",
    "        sorted_ypu = y_pu[sorted_index]\n",
    "        if num_items != None:\n",
    "            sorted_ypu = sorted_ypu[:num_items]\n",
    "        return video_ids, sorted_ypu\n",
    "    else:\n",
    "        return video_ids\n",
    "\n",
    "video_ids, sorted_ypu = predict_existing_user(user_id=user_id, num_items=10)\n",
    "\n",
    "# Display each video_id with its watch ratio\n",
    "for i in range(len(video_ids)):\n",
    "    print(\"Predict video id\", video_ids[i], \"with watch ratio\", sorted_ypu[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c723a70d",
   "metadata": {},
   "source": [
    "We now can evaluate how well does the recommendation system perform. For this, we will calculate the following metrics:\n",
    "\n",
    "### 🔹 Precision@K and Recall@K\n",
    "\n",
    "$$\n",
    "\\text{Precision@K} = \\frac{\\text{number of relevant recommended items in top-K}}{K}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Recall@K} = \\frac{\\text{number of relevant recommended items in top-K}}{\\text{total number of relevant items}}\n",
    "$$\n",
    "\n",
    "### 🔹 Normalised discount cumulative gain (NDCG)\n",
    "\n",
    "$$\n",
    "\\text{NDCG@K} = \\frac{\\text{DCG@K}}{\\text{IDCG@K}}\n",
    "$$\n",
    "\n",
    "where, \n",
    "\n",
    "$$\n",
    "\\text{DCG@K} = \\sum_{i=1}^{K} \\frac{2^{rel_i} - 1}{\\log_2(i+1)}\n",
    "$$\n",
    "where, $rel_i$ is the ground truth relevance score of the $i^{th}$ item in the top-K list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a02f1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(ranked_items, ground_truth, k):\n",
    "    hits = sum([1 for item in ranked_items[:k] if item in ground_truth])\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(ranked_items, ground_truth, k):\n",
    "    hits = sum([1 for item in ranked_items[:k] if item in ground_truth])\n",
    "    return hits / len(ground_truth)\n",
    "\n",
    "def ndcg_at_k(ranked_items, ground_truth, k):\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(ranked_items[:k]):\n",
    "        if item in ground_truth:\n",
    "            dcg += 1.0 / np.log2(i + 2)\n",
    "    idcg = sum([1.0 / np.log2(i + 2) for i in range(min(len(ground_truth), k))])\n",
    "    return dcg / idcg if idcg > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6bdf3",
   "metadata": {},
   "source": [
    "We suppose that a video is relevant to a user if the watch_ratio is 1 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffdd1e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 1s 3ms/step\n",
      "Precision@1 for user 76 is 1.0\n",
      "Recall@1 for user 76 is 0.0008920606601248885\n",
      "NDCG@1 for user 76 is 1.0\n",
      "\n",
      "Precision@10 for user 76 is 0.3\n",
      "Recall@10 for user 76 is 0.0026761819803746653\n",
      "NDCG@10 for user 76 is 0.42257499837058643\n",
      "\n",
      "Precision@100 for user 76 is 0.31\n",
      "Recall@100 for user 76 is 0.027653880463871544\n",
      "NDCG@100 for user 76 is 0.3338218276600255\n",
      "\n",
      "Precision@1000 for user 76 is 0.136\n",
      "Recall@1000 for user 76 is 0.12132024977698483\n",
      "NDCG@1000 for user 76 is 0.15556792354785912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Another random user\n",
    "user_id2 = 76\n",
    "\n",
    "relevant_user = y_df[y_df['user_id'] == user_id2]\n",
    "relevant_user = relevant_user[relevant_user['watch_ratio'] >= 1]\n",
    "relevant_videos = list(relevant_user['video_id'])\n",
    "\n",
    "recommended_videos = predict_existing_user(user_id2, get_score=False)\n",
    "\n",
    "for i in range(4):\n",
    "    i_pow = 10 ** i\n",
    "    print(f\"Precision@{i_pow} for user {user_id2} is\", precision_at_k(recommended_videos, relevant_videos, i_pow))\n",
    "    print(f\"Recall@{i_pow} for user {user_id2} is\", recall_at_k(recommended_videos, relevant_videos, i_pow))\n",
    "    print(f\"NDCG@{i_pow} for user {user_id2} is\", ndcg_at_k(recommended_videos, relevant_videos, i_pow))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da160fa",
   "metadata": {},
   "source": [
    "Precision@1 is 1 here, meaning that I have no problem with the cold start. It is however not the case for all users.\n",
    "\n",
    "Globally those metrics are ok, and users get 1 relevant video each 3-4 recommended. The recommender system seem to not be perfect at ranking items, but the issue is also that there are a lot of items and each user has not interacted with many of them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
